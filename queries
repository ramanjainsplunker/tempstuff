

index=_internal source=*license_usage.log TERM(type=Usage) earliest=-7d@d latest=@d
| fields idx, b, st, h, _time, date_wday
| eval h=if(len(h)=0 OR isnull(h),'(SQUASHED)',h)
| bin _time span=1d
| stats sum(b) AS b, dc(h) AS h by st idx date_wday
| stats avg(b) as avg_b, avg(h) AS Host_Count_per_Day by idx st
| eval Avg_MB_per_Day=round(avg_b/1024/1024,2)
| eval Avg_GB_per_Day=round(avg_b/1024/1024/1024,2)
| eval Avg_MB_per_Host=round(Avg_MB_per_Day/Host_Count_per_Day,2)
| eval Host_Count_per_Day=round(Host_Count_per_Day,0)
| rename st AS Sourcetype
| table idx, Sourcetype, Avg_MB_per_Day, Avg_GB_per_Day, Host_Count_per_Day, Avg_MB_per_Host
| sort Sourcetype

index="_internal" source="*/metrics.log" group=per_index_thruput
| eval gb=kb/1024/1024
| bin span=15m _time
| stats sum(gb) as true_indexed_gbs_every_15m by series


index=_introspection host=*  sourcetype=splunk_resource_usage component=Hostwide earliest=-8d@d latest=-0d@d 
| eval cpu_busy='data.cpu_system_pct'+'data.cpu_user_pct'
| bin span=1m _time
| stats p90(data.normalized_load_avg_1min) as load_avg , p90(cpu_busy) as cpu_busy by host



(component=PerProcess  index=_introspection sourcetype=splunk_resource_usage) 
| eval process='data.process', args='data.args', sid='data.search_props.sid', process_class=case((process == "splunk-optimize"),"index service",(((((process == "sh") OR (process == "ksh")) OR (process == "bash")) OR like(process,"python%")) OR (process == "powershell")),"scripted input",(process == "mongod"),"KVStore"), process_class=case(((process == "splunkd") AND ((like(args,"-p %start%") OR like(args,"service")) OR like(args,"%_internal_launch_under_systemd%"))),"splunkd server",((process == "splunkd") AND isnotnull(sid)),"search",((process == "splunkd") AND ((like(args,"fsck%") OR like(args,"recover-metadata%")) OR like(args,"cluster_thing"))),"index service",((process == "splunkd") AND (args == "instrument-resource-usage")),"scripted input",((like(process,"python%") AND like(args,"%/appserver/mrsparkle/root.py%")) OR like(process,"splunkweb")),"Splunk Web",isnotnull(process_class),process_class), process_class=if(isnull(process_class),"other",process_class) 
| bin _time span=1m 
| eval pid='data.pid', normalized_pct_cpu='data.normalized_pct_cpu' 
| stats latest(normalized_pct_cpu) AS resource_usage_dedup latest(process_class) AS process_class by pid, _time 
| stats sum(resource_usage_dedup) AS resource_usage by _time, process_class 
| timechart minspan=1m Perc90(resource_usage) AS "Resource Usage" by process_class limit=0 useother=false

| eval process_class=case( 'data.process_type'=="search","search", (role=="sh" AND ('data.process_type'=="process_runner" OR 'data.process_type'=="splunkd_server" OR 'data.process_type'=="splunkd_runner")) OR 'data.process_type'=="search_launcher" OR 'data.process_type'=="kvstore" OR 'data.process_type'=="splunk_web" OR role=="sh", "core services", match('data.process_type',"index") OR 'data.process_type'=="scripted_input" OR role=="idx" OR role=="idm" OR role=="c0m1","data services" ) 



(data.search_props.sid::* component=PerProcess index=_introspection sourcetype=splunk_resource_usage) 
| eval pid='data.pid', normalized_pct_cpu='data.normalized_pct_cpu', sid='data.search_props.sid', provenance=if(isnotnull('data.search_props.provenance'),'data.search_props.provenance',"unknown") 
| bin _time span=10s 
| stats latest(normalized_pct_cpu) AS resource_usage_dedup by _time, provenance, sid, pid 
| stats sum(resource_usage_dedup) AS sum_resource_usage by _time, provenance 
| eval sum_resource_usage=round((sum_resource_usage / 100.0),2) 
| timechart minspan=10s Median(sum_resource_usage) AS "Median of resource usage" by provenance




index=_audit TERM(action=search) sourcetype=audittrail search_id!="'rsa_*" total_run_time>0 earliest=-1d@d latest=-0d@d NOT (TERM(user=cmon_user) TERM(user=internal_monitoring) TERM(user=ops_admin)) 
| eval user = if(user="n/a", null(), user) 
| rex field=_raw "[^\_]index=\"?(?<Index>[\_a-zA-Z\-\:]{2,})\"?" max_match=0 
| rex field=_raw "[^\_]sourcetype=\"?(?<sourcetype>[\_a-zA-Z\-\:]{2,})\"?" max_match=0 
| eval Index=lower(Index) 
| rex field=search_id "\'(?P<search_id>.*?)\'" 
| eval search=if(isnull(savedsearch_name) OR savedsearch_name=="", search, savedsearch_name) 
| eval search_type=case(match(search_id,"^SummaryDirector_"),"summarization",match(savedsearch_name,"^_ACCELERATE_"),"acceleration",match(search_id,"^((rt_)?scheduler_|alertsmanager_)"),"scheduled",match(search_id,"\\d{10}\\.\\d+(_[0-9A-F]{8}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{12})?$"),"ad hoc",true(),"other") 
| stats values(sourcetype) as sourcetype, min(_time) as _time, values(user) as user, latest(info) as status, max(total_run_time) as total_run_time, values(Index) as Index , first(search) as search, first(search_type) as search_type, first(apiStartTime) as apiStartTime, first(apiEndTime) as apiEndTime , first(search_et) as search_et, first(search_lt) as search_lt, max(searched_buckets) as searched_buckets, max(scan_count) as scan_count, max(considered_events) as considered_events, max(event_count) as event_count, max(result_count) as result_count, first(exec_time) as exec_time by search_id 
| bin _time span=1d 
| stats count p90(total_run_time), avg(total_run_time) by search_type _time
|eventstats sum(count) as total_per_day by _time

index=_audit earliest=-1d@d latest=-0d@d NOT (TERM(user=cmon_user) TERM(user=internal_monitoring) TERM(user=ops_admin))| bin _time span=1d
| eval _time = _time+86399 | stats count(sourcetype_count__*) as datatype_* by _time
| transpose
|rename column as stypes, "row 1" as searches
| where stypes!="_time"


dashboard panel runs-->

(index=_audit action=search search_id NOT typeahead NOT "search_id='rsa_*" host=sh*)  earliest=-1d@d latest=-0d@d
| rex field=_raw ", search=\'(?<thesearch>.*)" 
| rex max_match=100 field=search "(?:[^\"\']|^)index=(?<indexes>[^\s\=]+)" 
| rex max_match=100 field=search "tag=(?<tags>[^\s+\||\)]+)" 
| rex max_match=100 field=search "eventtype=(?<eventtypes>[^\s+\||\)]+)" 
| rex max_match=100 field=search "(?<macros>\`[^\s]+\`)" 
| eval total_days_searched=(search_lt-search_et)/86400 
| eval total_hours_searched=total_days_searched*24 
| eval total_hours_searched=round(total_hours_searched,1) 
| eval total_days_searched=round(total_days_searched,0) 
| eval search_id=trim(search_id,"\'") 
| eval search_id=coalesce(search_id,sid) 
| eval origSid=search_id 
| eval app = app 
| rex field=search_id "subsearch_(?<search_id>.*)_\d+\.\d+" 
| eval api_et=if(api_et="N/A", search_et, api_et) 
| eval total_hours_searched=if(api_et="N/A", "AllTime",total_hours_searched) 
| eval total_days_searched=if(api_et="N/A", "AllTime",total_days_searched) 
| eval provenance=if(provenance="N/A",NULL,provenance) 
| eval provenance=if(provenance="UI:LocateData",NULL,provenance) 
| stats values(host) as host sum(duration_command_search_rawdata_bucketcache_miss) AS duration__raw_cache_miss sum(invocations_command_search_index_bucketcache_miss) as count_index_cache_miss sum(invocations_command_search_rawdata_bucketcache_miss) as count_rawdata_cache_miss values(total_hours_searched) AS total_hours_searched values(total_days_searched) AS total_days_searched values(user) AS users values(indexes) AS indexes values(macros) AS macros values(eventtypes) AS eventtypes values(tags) AS tags last(search) AS search values(savedsearch_name) AS savedsearch_name max(total_run_time) AS run_time values(result_count) AS result_count values(event_count) AS event_count values(searched_buckets) AS searched_buckets values(info) AS info values(provenance) AS provenance dc(origSid) AS numofsearchesinquery by search_id app 
| eval total_cache_miss=count_index_cache_miss+count_rawdata_cache_miss 
| search provenance=*Dashboard* 
| eval total_hours_searched=round(total_hours_searched,1) 
| stats count as number_of_searches_run dc(savedsearch_name) as num_panels values(sh_label) as host max(run_time) AS max_run_time avg(run_time) AS avg_run_time sum(run_time) AS sum_run_time sum(total_cache_miss) as total_cache_miss sum(result_count) AS result_count sum(event_count) AS event_count sum(searched_buckets) AS searched_buckets values(users) as users by provenance app 
| eval avg_run_time=round(avg_run_time,1) 
| eval provenance=replace(provenance, "UI:Dashboard:", "") 
| rename provenance as dashboard 
| sort - sum_run_time host


Drill into specific dashboard -->

(index=_audit action=search search_id NOT typeahead NOT "search_id='rsa_*" host=sh*) earliest=-1d@d latest=-0d@d
| rex field=_raw ", search=\'(?<thesearch>.*)" 
| rex max_match=100 field=search "(?:[^\"\']|^)index=(?<indexes>[^\s\=]+)" 
| rex max_match=100 field=search "tag=(?<tags>[^\s+\||\)]+)" 
| rex max_match=100 field=search "eventtype=(?<eventtypes>[^\s+\||\)]+)" 
| rex max_match=100 field=search "(?<macros>\`[^\s]+\`)" 
| eval total_days_searched=(search_lt-search_et)/86400 
| eval total_hours_searched=total_days_searched*24 
| eval total_hours_searched=round(total_hours_searched,1) 
| eval total_days_searched=round(total_days_searched,0) 
| eval search_id=trim(search_id,"\'") 
| eval search_id=coalesce(search_id,sid) 
| eval origSid=search_id 
| eval app = app 
| rex field=search_id "subsearch_(?<search_id>.*)_\d+\.\d+" 
| eval api_et=if(api_et="N/A", search_et, api_et) 
| eval total_hours_searched=if(api_et="N/A", "AllTime",total_hours_searched) 
| eval total_days_searched=if(api_et="N/A", "AllTime",total_days_searched) 
| eval provenance=if(provenance="N/A",NULL,provenance) 
| eval provenance=if(provenance="UI:LocateData",NULL,provenance) 
| stats values(host) as host sum(duration_command_search_rawdata_bucketcache_miss) AS duration__raw_cache_miss sum(invocations_command_search_index_bucketcache_miss) as count_index_cache_miss sum(invocations_command_search_rawdata_bucketcache_miss) as count_rawdata_cache_miss values(total_hours_searched) AS total_hours_searched values(total_days_searched) AS total_days_searched values(user) AS users values(indexes) AS indexes values(macros) AS macros values(eventtypes) AS eventtypes values(tags) AS tags last(search) AS search values(savedsearch_name) AS savedsearch_name max(total_run_time) AS run_time values(result_count) AS result_count values(event_count) AS event_count values(searched_buckets) AS searched_buckets values(info) AS info values(provenance) AS provenance dc(origSid) AS numofsearchesinquery by search_id app 
| eval total_cache_miss=count_index_cache_miss+count_rawdata_cache_miss 
| search provenance=UI:Dashboard:* 
| eval total_hours_searched=round(total_hours_searched,1) 
| stats count as number_of_runs values(sh_label) as host values(total_hours_searched) AS total_hours_searched values(total_days_searched) AS total_days_searched values(indexes) AS indexes values(macros) AS macros values(eventtypes) AS eventtypes values(tags) AS tags last(search) AS search max(run_time) AS max_run_time avg(run_time) AS avg_run_time sum(run_time) AS sum_run_time sum(total_cache_miss) as total_cache_miss max(result_count) AS result_count max(event_count) AS event_count max(searched_buckets) AS searched_buckets values(info) AS info values(numofsearchesinquery) AS numofsearchesinquery values(users) as users by savedsearch_name provenance 
| eval avg_run_time=round(avg_run_time,1) 
| eval provenance=replace(provenance, "UI:Dashboard:", "") 
| rename provenance as dashboard 
| sort - sum_run_time


Refresh inclusion and panel numbers -->


| rest splunk_server=local /servicesNS/-/-/data/ui/views timeout=900 
| rename eai:acl.* as *, eai:appName as appName, eai:data as data, eai:userName as username 
| fields title appName username owner data app 
| rex field=data "(?P<usecases>\<query\>)" max_match=0 
| rex field=data "\<title\>(?P<usecaselist>.*?)\<\/title\>" max_match=0 
| rex field=data "refresh=(?P<int1>.*?)( |\>)" max_match=0 
| rex field=data "refresh>(?P<int2>.*?)\<" max_match=0 
| eval interval = coalesce(int1,int2) 
| eval usecasecount=mvcount(usecases) 
| rename title as dashboardName 
| fields dashboardName app username usecasecount interval owner data 
| search app!="splunk_monitoring_console" app!="splunk_instance_monitoring" 
| eval _time = now() 
| bin _time span=1d 
| eval _time = _time-1


